Allow different kinds of messages to be received trx/non-trx from the same queue, e.g. we peek a message, discover its type and vary the transactionality of the receive.
*or* we receive all messages transactionally (unless a queue is non-trx).  Then, upon discovering its type, we complete the UoW even
before pass the message to the message handlers.  If a message is a regular, transactional message we call UoW complete only after
all processing has been completed.

[A] Specify ordering of message handlers
[A] Prevent subscriptions to object and/or base IMessage-like type?
[A] MessageBus should get transport based upon address.
[A] UnitOfWorkTransport (only when complete is called does it dispatch all enqueued messages to the actual endpoints)
    - UnitOfWorkEndpoint???
[A] Standardize assembly naming, packaging, and ILMerge quirks.
[A] Full unit and integration tests.
[A] Documentation and examples.

[B] Support for multiple containers (Castle, SM, Ninject, Unity) with fluent builders

[B] Perhaps we should promote the concept of an "Address" to be first class?
    - using System.Uri (we can use user/pass values for authenticated endpoints)
    - we could also use querystring the query string values to wrap endpoints in endpoints,
      e.g. an msmq address inside of an http address

[B] IdempotentReceiver
    - when a message is received, we ensure that we've only received it once and that,
      when the UoW is complete, the message is considered received and then ignored
    - This would most likely occur in memory where we could track the last X,000 messages
      (or X minutes) received and de-duplicate on that...

[B] Generic host
[C] Timeout Manager

[B] ISplitMessagesIntoPackets and IReassembleMessagesFromPackets
    - allows smaller payloads to be split and transferred across the wire when the
      infrastructure has a highly restrictive message size, e.g. Azure & SQS.)
    - Packet: GroupId:Guid, Sequence/Index:int, Bytes:int, FinalPacket:bool
    - Split(Stream, MaxPacketSize):IEnumerable<Packet>
    -  Combine(Packet):Stream (null if !complete)
    - Expiration?  All packets should expire at the same time and cause the entire "stream" to expire
    - it feels like the endpoint itself should handle this responsibility with the help of some
      collaborator code

[C] Additional endpoint connectors, e.g. Azure, SQS, RabbitMQ, ActiveMQ, Qpid, etc.

[C] Additional transports, e.g. HttpTransport, FtpTransport, SmtpTransport, etc.

[C] MessageBus should receive a Func<address, ITransportMessages> instead of just ITransportMessages
 - this allows us to dispatch to transports based upon the address scheme, e.g. msmq://, smtp://, ftp://, http(s)://
 - for non-queued (and non-durable transports), we'll probably want to create a small DB queue infrastructure
   such that outbound messages are committed as part of the UoW and dispatched async on a separate thread.

[C] SinglePhaseCommitReceiver/Sender
 - The message is received in a separate transaction from the work against the DB
 - This really works well for NoSQL implementations...
 - When the "DB" UoW is done, it commits and tracks the incoming message that was
   associated with the UoW.
 - Furthermore, it writes its results to an outbound "queue" table.
 - It pushes the message to publish onto an in-memory "queue" which another thread
   it monitoring and publishing from
 - This thread then does the publish and removes the item from the queue table.
 - The entire objective is to completely avoid 2PC so as to enable use of other
   storage engines that may not support 2PC outright.

[C] ITransportFiles (ITransportStreams?)
 - this is in contrast to ISplitMessagesIntoPackets which keeps the payload in memory
   whereas ITransportFiles doesn't attempt to keep everything in memory)
 - it still needs to be aware of expiration

[B] ReplicatedSubscriptionStorage
 - Publisher notifies "central" subscription storage of intent to publish along with
   types of messages it will publish and expiration of publish (max publisher lifetime?).
   This occurs when the SubscriptionStorage is initialized, e.g. ctro

 - "Central" subscription storage receives publisher notification/annoucment and adds
   the annocument/life of messages publisher will publish to its list of publishers

 - Subscriber sends a sub/unsub request to the "publisher subscription endpoint" as normal.

 - When a sub/unsub request arrives, the central storage saves it to the DB and then iterates
   through the publishers and finds the publisher(s) that match the associated message types

 - central publisher subscription endpoint then forwards* the corresponding sub/unsub message
   to all publishers for the particular message type.
   * forwards = new sub/unsub message with just the associated types

 - the main advantage of this is that everything can be in memory for the publisher, e.g.
   when it goes to publish, it doesn't have to query a database.  It can simply go to its
   DiskBackedInMemorySubscriptionStorage instance.

 - The publisher would persist all sub/unsubs to disk but retain a copy in memory to avoid
   a disk read for every single invocation of "publish".

   OPTIONAL STUFF:
 - Heartbeat: Publisher renews "lifecycle lease" every X hours?
 - "Central" subscription storage stops forwarding Subscribe/Unsubscribe requests after X missed heartbeats
 - When publisher wakes up, central subscription store gets HB annoucment and forwards all corresponding
   state to publisher

 - this all could potentially be done using event sourcing with snapshots?